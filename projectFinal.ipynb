{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test change pt.5\n",
    "sdasdasdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the latest versions of said modules upon the creation of this project\n",
    "\n",
    "# Uncomment the line below to install dependencies for the required libraries\n",
    "#!pip install -r requirements.txt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "**Pandas** is a library that provides many tools for working with data in Python. It is imported to use these tools to performe wide variety of data manipulation and analysis tasks. In this project, pandas is mainly utilized for reading and writing CSV files, including importing the dataset, adding headers, and reviewing its contents using the df.head(n) and df.tail(n) methods. Additionally, functions are used to convert '?' values to \"NaN\" to identify non-numerical values. Pandas is also employed to obtain a brief overview of the dataset's information, data types, and descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 1.5.3\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "**NumPy** is a widely used library for Python that simplifies data analysis and scientific computing by providing a variety of useful features for working with numerical data in arrays and matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 1.24.1\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib\n",
    "**matplotlib** is a module within the matplotlib library in Python that is utilized for making plots and visualizing data. It offers a user-friendly interface to create a variety of plots, such as line plots, scatter plots, bar plots, and histograms. \n",
    "\n",
    "// pylab & pylot are used; explain each briefly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 3.6.3\n",
    "import matplotlib.pylab as plt_lab\n",
    "import matplotlib.pyplot as plt_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn\n",
    "**Seaborn** is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. Seaborn is used to create a heatmap to visualize the correlation between the features in the dataset.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn 0.12.2\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy\n",
    "**SciPy** is a Python library that is used to perform scientific computing and technical computing. It is used to perform a variety of mathematical, scientific, and engineering tasks. In this project, SciPy is used to perform a one-way ANOVA test to determine if there is a significant difference in the means of the three groups.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy 1.2.1\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "**Scikit-learn** is a Python library that is used for machine learning. It is used to perform a variety of machine learning tasks, such as classification, regression, and clustering. In this project, Scikit-learn is used to perform a logistic regression to predict the class of a new instance.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn 1.2.1\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ipywidgets\n",
    "**Ipywidgets** is a Python library that is used to create interactive widgets for Jupyter notebooks. It is used to create a slider to select the number of features to be used in the logistic regression model.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipywidgets 8.0.4\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tqdm\n",
    "**tqdm** is a Python library that is used to create progress bars for loops. It is used to create a progress bar to show the progress of the logistic regression model.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm 4.64.1\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Briefly describe the dataset used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "\n",
    "print(\"The header names are: \", headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and save the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./auto.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset, header=None, names=headers)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic insight of the dataset\n",
    "// general insight about the data as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dataset has\", df.shape[0] , \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleansing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert '?' to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('?', np.nan)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN = df[df.isna().any(axis=1)]\n",
    "NaN.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of NaN values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull()\n",
    "# missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the number of missing values on each column\n",
    "for column in missing_values.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_values[column].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the summary above, each column has 205 rows of data and seven of the columns containing missing data:\n",
    "\n",
    "<ol>\n",
    "    <li>\"normalized-losses\": 41 missing data</li>\n",
    "    <li>\"num-of-doors\": 2 missing data</li>\n",
    "    <li>\"bore\": 4 missing data</li>\n",
    "    <li>\"stroke\" : 4 missing data</li>\n",
    "    <li>\"horsepower\": 2 missing data</li>\n",
    "    <li>\"peak-rpm\": 2 missing data</li>\n",
    "    <li>\"price\": 4 missing data</li>\n",
    "</ol>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct data format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "### Analyze individual feature patterns using visualization\n",
    "### Analyze the relationship between features and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
