{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Gathering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the latest versions of said modules upon the creation of this project\n",
    "\n",
    "# Uncomment the line below to install dependencies for the required libraries\n",
    "#!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "**Pandas** is a library that provides many tools for working with data in Python. It is imported to use these tools to performe wide variety of data manipulation and analysis tasks. In this project, pandas is mainly utilized for reading and writing CSV files, including importing the dataset, adding headers, and reviewing its contents using the df.head(n) and df.tail(n) methods. Additionally, functions are used to convert '?' values to \"NaN\" to identify non-numerical values. Pandas is also employed to obtain a brief overview of the dataset's information, data types, and descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 1.5.3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "**NumPy** is a widely used library for Python that simplifies data analysis and scientific computing by providing a variety of useful features for working with numerical data in arrays and matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 1.24.1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib\n",
    "**matplotlib** is a module within the matplotlib library in Python that is utilized for making plots and visualizing data. It offers a user-friendly interface to create a variety of plots, such as line plots, scatter plots, bar plots, and histograms. \n",
    "\n",
    "// pylab & pylot are used; explain each briefly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 3.6.3\n",
    "import matplotlib.pylab as plt_lab\n",
    "import matplotlib.pyplot as plt_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn\n",
    "**Seaborn** is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. Seaborn is used to create a heatmap to visualize the correlation between the features in the dataset.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn 0.12.2\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy\n",
    "**SciPy** is a Python library that is used to perform scientific computing and technical computing. It is used to perform a variety of mathematical, scientific, and engineering tasks. In this project, SciPy is used to perform a one-way ANOVA test to determine if there is a significant difference in the means of the three groups.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy 1.2.1\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "**Scikit-learn** is a Python library that is used for machine learning. It is used to perform a variety of machine learning tasks, such as classification, regression, and clustering. In this project, Scikit-learn is used to perform a logistic regression to predict the class of a new instance.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn 1.2.1\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ipywidgets\n",
    "**Ipywidgets** is a Python library that is used to create interactive widgets for Jupyter notebooks. It is used to create a slider to select the number of features to be used in the logistic regression model.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipywidgets 8.0.4\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tqdm\n",
    "**tqdm** is a Python library that is used to create progress bars for loops. It is used to create a progress bar to show the progress of the logistic regression model.\n",
    "\n",
    "// copilot generated text; needs to proofread and revised!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm 4.64.1\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. 1985 Auto Imports Database\n",
    "This dataset is donated by Jeffrey C. Schlimmer on May 19, 1987. The dataset's source are:\n",
    "1. 1985 Model Import Car and Truck Specifications, 1985 Ward's Automotive Yearbook\n",
    "2. Personal Auto Manuals, Insurance Services Office, 160 Water Street, New York, NY 10038\n",
    "3. Insurance Collision Report, Insurance Institute for Highway Safety, Watergate 600, Washington, DC 20037"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "The attributes of this dataset represent:\n",
    "- specification of an auto in terms of various characteristics\n",
    "- assigned insurance risk rating (symboling)\n",
    "- normalized losses in use as compared to other cars\n",
    "\n",
    "    *This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **symboling** - the degree to which the auto is more risky than its price indicates (3 = very risky, -3 = very safe)\n",
    "2. **normalized-losses** - normalized loss value for a particular car; may represent the financial loss or cost associated with a car\n",
    "3. **make** - make of the car (e.g., Honda, Toyota, etc.)\n",
    "4. **fuel-type** - type of fuel used by the car (gas or diesel)\n",
    "5. **aspiration** - type of engine aspiration (standard or turbocharged)\n",
    "6. **num-of-doors** - number of doors on the car \n",
    "7. **body-style** - style of the car's body (e.g., sedan, hatchback, etc.)\n",
    "8. **drive-wheels** - configuration of the car's drive wheels (front, rear, or four-wheel)\n",
    "9. **engine-location** - location of the car's engine (front or rear)\n",
    "10. **wheel-base** - distance between the centers of the front and rear wheels \n",
    "11. **length** - length of the car \n",
    "12. **width** - width of the car \n",
    "13. **height** - height of the car\n",
    "14. **curb-weight** - weight of the car without any passengers or cargo\n",
    "15. **engine-type** - type of engine in the car (e.g., dohc, ohc, etc.)\n",
    "16. **num-of-cylinders** - number of cylinders in the car's engine\n",
    "17. **engine-size** - size of the car's engine\n",
    "18. **fuel-system** - fuel system used by the car (e.g., mpfi, 2bbl, etc.)\n",
    "19. **bore** - diameter of the car's cylinders\n",
    "20. **stroke** - distance traveled by the car's pistons during one engine cycle\n",
    "21. **compression-ratio** - ratio of the volume of the combustion chamber at the bottom of the piston stroke to the volume at the top\n",
    "22. **horsepower** - power of the car's engine\n",
    "23. **peak-rpm** - highest number of revolutions per minute the car's engine can make\n",
    "24. **city-mpg** - number of miles per gallon the car can get in the city\n",
    "25. **highway-mpg** - number of miles per gallon the car can get on the highway\n",
    "26. **price** - price of the car"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace dataset headers with attribute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns to their proper attribute labels\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and save the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./auto.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset, header=None, names=headers)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Basic insight on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dataset has\", df.shape[0] , \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The types of the columns are as follows:\\n\", df.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe\n",
    "This provides a statistical summary of all columns, including object-typed attributes.\n",
    "\n",
    "*Note: Some values in the table below show as \"NaN\" because their respective columns contain missing data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = \"all\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info\n",
    "This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Cleansing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Identify and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"?\" to NaN\n",
    "df.replace(\"?\", np.nan, inplace = True)\n",
    "\n",
    "# Identify missing values\n",
    "print(\"The number of missing values per column are:\\n\", df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are several ways to deal with missing data:\n",
    "1. **Drop data** - a data point (row) is removed if it contains a missing value\n",
    "2. **Replace data** - missing value is replaced by mean or frequency\n",
    "3. **Drop attribute** - the entire column is removed if it contains enough missing values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Losses\n",
    "The normalized losses attribute has 41 missing values, which is about 20% of the total dataset, which is insignificant enough for the attribute to be dropped. Furthermore, since it is a numerical variable and the data distribution is barely asymmetrical, replacing the missing values with the mean is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of normalized losses\n",
    "plt_lab.hist(df[\"normalized-losses\"].astype(\"float\"), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean value for normalized losses\n",
    "mean_normalized_losses = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of normalized losses:\", mean_normalized_losses)\n",
    "\n",
    "# replace NaN with mean value in \"normalized-losses\" column\n",
    "df[\"normalized-losses\"].replace(np.nan, mean_normalized_losses, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num of Doors\n",
    "The num of doors attribute has only 2 missing values. It is a categorical variable, so replacing the missing values with the most frequent value is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of each value in the \"num-of-doors\" column\n",
    "print(\"The frequency of each value in the num-of-doors column is:\\n\", df[\"num-of-doors\"].value_counts())\n",
    "\n",
    "# replace the missing 'num-of-doors' values by the most frequent\n",
    "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bore\n",
    "The bore attribute has only 4 missing values. It is a numerical variable, so replacing the missing values with the mean is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean value for bore\n",
    "mean_bore = df[\"bore\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of bore:\", mean_bore)\n",
    "\n",
    "# replace NaN with mean value in \"bore\" column\n",
    "df[\"bore\"].replace(np.nan, mean_bore, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke\n",
    "The stroke attribute has only 4 missing values. It is a numerical variable, so replacing the missing values with the mean is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean value for stroke\n",
    "mean_stroke = df[\"stroke\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of stroke:\", mean_stroke)\n",
    "\n",
    "# replace NaN with mean value in \"stroke\" column\n",
    "df[\"stroke\"].replace(np.nan, mean_stroke, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horsepower\n",
    "The horsepower attribute has only 2 missing values. It is a numerical variable, so replacing the missing values with the mean is recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean value for horsepower\n",
    "mean_horsepower = df[\"horsepower\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average horsepower:\", mean_horsepower)\n",
    "\n",
    "# replace NaN with mean value in \"horsepower\" column\n",
    "df[\"horsepower\"].replace(np.nan, mean_horsepower, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak RPM\n",
    "The peak rpm attribute has only 2 missing values. It is a numerical variable, so replacing the missing values with the mean is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean value for peak-rpm\n",
    "mean_peak_rpm = df[\"peak-rpm\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average peak rpm:\", mean_peak_rpm)\n",
    "\n",
    "# replace NaN with mean value in \"peak-rpm\" column\n",
    "df[\"peak-rpm\"].replace(np.nan, mean_peak_rpm, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price\n",
    "The price attribute has only 4 missing values. However, it is the target variable. As such, the rows with missing values are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows that do not have price data\n",
    "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
    "\n",
    "# reset index, because we droped two rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Data standardization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Data normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Binning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Indicator variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing individual feature patterns using visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Numerical Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
